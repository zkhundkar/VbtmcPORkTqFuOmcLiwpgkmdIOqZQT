{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Engineer Nanodegree\n",
    "## Capstone Project - InstaCart Market Basket Analysis\n",
    "\n",
    "### Pre-processing and feature engineering\n",
    "\n",
    "This notebook handles cleaning up the data and creating engineered features to tease out general features about the user and product. We will use the hdf files we created during exploration for fast read access to the raw data and save the features we create and some interim data that is computational expensive so we don't need to repeat those calculations between notebook sessions and across notebooks\n",
    "\n",
    "### User-product features\n",
    "_raw features _\n",
    " - `place_in_cart` : rank in which product was placed in cart\n",
    " \n",
    "_engineered features_\n",
    " - `up_times` : # times user purchased this product\n",
    " - `up_reord_prob` : (conditional) given user bought product, probability that they reordered it?\n",
    " - `up_oprob` : probability user purchases this product in each order\n",
    " - `up_avg_days` : average number of days between product in order/basket\n",
    " - `ip_last_reord` : whether product was reordered the last time it was in a user's basket\n",
    " - `u_aprob` : probablity (weighted) user bought a product from this aisle in an order\n",
    " - `u_a_reord` : probablity that a product from this aisle was reordered\n",
    " - `up_cart_rank` : average rank in cart\n",
    "\n",
    " - `up_dow` : average day of week order was placed\n",
    " - `up_tod` : average hour (24 hr) of day the order was placed\n",
    " - `u_a_pcount` : average # of products purchased by user\n",
    " - `u_a_reord` : (conditional) probability that products from this aisle were reordered\n",
    " - `ua_ocount` : number of orders with products from this aisle \n",
    "\n",
    "### User features  \n",
    " - `uo_count` : # orders placed by user\n",
    " - `ubasket_avg` : average basket size for user\n",
    " - `top-1` - `top-10` : aisle_id of 10 most frequently ordered products aggregated by aisle\n",
    "\n",
    "### Basket features\n",
    "_raw features_\n",
    "\n",
    "\n",
    " impute NaN days_since_prior_order as mean\n",
    "    `outlier` distribute days_since_prior_order=30 randomly into 20 bins between 30 and 50\n",
    " - `30plus` : flag to indicate this was likely an aggregated piece of information\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded numpy and pandas libraries\n",
      "Wall time: 1.62 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## Most of the calculation used for preprocessed are in the caps-utils.py module\n",
    "%run cap-utils.py\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# Import libraries necessary for this project\n",
    "#import numpy as np\n",
    "#import pandas as pd\n",
    "import os\n",
    "\n",
    "_datapath = './'\n",
    "os.chdir(_datapath)\n",
    "\n",
    "# RAW_STORE = 'instacart_raw.hdf5'\n",
    "# HDF_STORE = 'instacart.hdf5'\n",
    "# FVARS_STORE = 'features.hdf5'\n",
    "# STATS_STORE = 'stats.hdf5'\n",
    "# BASKETS = 'baskets.hdf5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Note on computational resources\n",
    "Several of the preprocessing steps take significant computational resources. I ran this on a AMD Phenom II quad-processer (quite old) but with 24 GB RAM. Expanding the `priors` table or calculating the user-product features takes up more than 8GB during run time. Jupyter will 'crash' with a memory error if the machine does not have sufficient memory. During testing and developing the python code, I used the DataFrame `sample` function liberally.\n",
    "\n",
    "### Augment the orders and products tables\n",
    "\n",
    "1. We will handle missing values in orders and also add a column containing the cumulative sum of days between orders. This will be used to calculate the days between when a particular product is ordered\n",
    "2. We will also add the depart_id and aisle_id to the priors table. We will do this to the entrire priors table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading orders datasets ...\n",
      "Loading priors datasets ...\n",
      "Loading products datasets ...\n",
      "Wall time: 1.71 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "d = get_from_hdf(['orders', 'priors', 'products'], RAW_STORE)\n",
    "orders = d['orders']\n",
    "priors = d['priors']\n",
    "products = d['products']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   order_id  user_id  eval_set  order_number  order_dow  order_hour_of_day  \\\n",
      "0   2539329        1         0             1          2                  8   \n",
      "1   2398795        1         0             2          3                  7   \n",
      "2    473747        1         0             3          3                 12   \n",
      "3   2254736        1         0             4          4                  7   \n",
      "4    431534        1         0             5          4                 15   \n",
      "\n",
      "   days_since_prior_order  30plus_days     csum_ds    log_ds  \n",
      "0               11.114836            0   11.114836  2.494431  \n",
      "1               15.000000            0   26.114836  2.772589  \n",
      "2               21.000000            0   47.114836  3.091042  \n",
      "3               29.000000            0   76.114836  3.401197  \n",
      "4               28.000000            0  104.114836  3.367296  \n",
      "Index([u'order_id', u'user_id', u'eval_set', u'order_number', u'order_dow',\n",
      "       u'order_hour_of_day', u'days_since_prior_order', u'30plus_days',\n",
      "       u'csum_ds', u'log_ds'],\n",
      "      dtype='object')\n",
      "Wall time: 9.99 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "preprocess_orders(orders)\n",
    "print orders.head()\n",
    "print orders.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'order_id', u'product_id', u'add_to_cart_order', u'reordered',\n",
      "       u'department_id', u'aisle_id'],\n",
      "      dtype='object')\n",
      "Wall time: 42.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "priors = add_product_groups(priors, products)\n",
    "print priors.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We need to expand the products table with `user_id` and calculate the days elapsed between orders for a specific user and product\n",
    "\n",
    "This calculation turned out to be very costly using a lambda expression in a DataFrame `aggregate` function. I implemented this using a python loop manipulating the data as a numpy matrix. Even with the speedup from the vectorized logic, calculating `ds_last` was one of the three slowest steps in the pre-processing stage.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected all orders.\n",
      "32434489 product orders\n",
      "Index([u'order_id', u'user_id', u'eval_set', u'order_number', u'order_dow',\n",
      "       u'order_hour_of_day', u'days_since_prior_order', u'30plus_days',\n",
      "       u'csum_ds', u'log_ds', u'product_id', u'add_to_cart_order',\n",
      "       u'reordered', u'department_id', u'aisle_id'],\n",
      "      dtype='object')\n",
      "Wall time: 1min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# This code block takes a long time (and a lot of memory). For testing, we can take samples instead\n",
    "# option 1 - get_hist_chunk(orders, priors, all=True) - the whole dataset \n",
    "#               (90 s. Check the next step though)\n",
    "# option 2 - get_hist_chunk(orders, priors, frac=0.001) - randomly selects 0.1% of the users (45 s)\n",
    "# \n",
    "ps=get_hist_chunk(orders, priors, all=True)\n",
    "print \"{} product orders\".format(len(ps))\n",
    "print ps.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32434489 Index([u'user_id', u'product_id', u'order_number', u'ds_last'], dtype='object')\n",
      "4 Index([u'user_id', u'product_id', u'order_number', u'ds_last'], dtype='object')\n",
      "Wall time: 3min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# The routine does this sort - showing here for reference\n",
    "#      ps.sort_values(by=['user_id', 'product_id', 'order_number'])\n",
    "g = user_product_ds_last(ps)\n",
    "#print ps[['user_id','product_id','order_number']].head(10)\n",
    "print len(g.columns), g.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32434489 16 Index([u'order_id', u'user_id', u'eval_set', u'order_number', u'order_dow',\n",
      "       u'order_hour_of_day', u'days_since_prior_order', u'30plus_days',\n",
      "       u'csum_ds', u'log_ds', u'product_id', u'add_to_cart_order',\n",
      "       u'reordered', u'department_id', u'aisle_id', u'ds_last'],\n",
      "      dtype='object')\n",
      "Wall time: 1min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ps = ps.merge(g, on=['user_id', 'product_id', 'order_number'])\n",
    "del g\n",
    "print len(ps), len(ps.columns), ps.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We calculated `ds_last` for the entire `orders_products` (aka `priors`) table _ONCE_ and saved it in hdf format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ps.to_hdf(HDF_STORE,'aug-priors')\n",
    "#ps=pd.read_hdf(HDF_STORE, 'aug-priors')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate user-product features from order history \n",
    "\n",
    "We calculate the features from the historical data, i.e., exclude order from the training and test sets.\n",
    "\n",
    "This step is computational expensive.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 13307953 entries, 0 to 13307952\n",
      "Data columns (total 18 columns):\n",
      "user_id          int64\n",
      "aisle_id         int16\n",
      "product_id       int64\n",
      "up_cart_rank     float64\n",
      "up_avg_days      float64\n",
      "up_in_last       int8\n",
      "up_times         int64\n",
      "up_reord_prob    float64\n",
      "up_last_reord    int8\n",
      "uo_count         int16\n",
      "ubasket_avg      float16\n",
      "up_prob          float64\n",
      "up_dow           float16\n",
      "up_tod           float16\n",
      "up_30_avg        float16\n",
      "ua_ocount        int16\n",
      "u_a_reord        float64\n",
      "u_a_pcount       float64\n",
      "dtypes: float16(4), float64(6), int16(3), int64(3), int8(2)\n",
      "memory usage: 1.2 GB\n",
      "None\n",
      "Wall time: 453 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#phist = ps[ps.eval_set == 0]\n",
    "up_feat = user_product_features(phist)\n",
    "up_feat['aisle_id'] = up_feat['aisle_id'].astype('int16')\n",
    "print up_feat.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "up_feat['uo_count']=up_feat['uo_count'].astype('int16')\n",
    "up_feat['ubasket_avg']=up_feat['ubasket_avg'].astype('float16')\n",
    "up_feat['up_dow']=up_feat['up_dow'].astype('float16')\n",
    "up_feat['up_tod']=up_feat['up_tod'].astype('float16')\n",
    "up_feat['ua_ocount']=up_feat['ua_ocount'].astype('int16')\n",
    "up_feat['up_30_avg']=up_feat['up_30_avg'].astype('float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "up_feat.to_hdf(FVARS_STORE, \"up_feat\")\n",
    "try:\n",
    "    del up_feat\n",
    "except:\n",
    "    pass\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    del products, priors\n",
    "except:\n",
    "    pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate frequently purchased products (grouped in aisles)  from order history \n",
    "\n",
    "We calculate the number of products from each aisle in each user's purchase history. We then identified 10 aisles with the most number of products for each user and placed the aisle id in 10 columns `top-1, top-2, ... top-10`, in rank order.\n",
    "\n",
    "This step is computational expensive.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32434489 product ordered\n",
      " ..  including products from 23338453 aisles\n",
      " .. 206209 users\n",
      "Wall time: 4min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ps.sort_values(by=[\"user_id\", 'order_id'], inplace=True)\n",
    "ga=build_user_topn_aisles(ps, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 206209 entries, 0 to 206208\n",
      "Data columns (total 11 columns):\n",
      "user_id    206209 non-null int32\n",
      "top-1      206209 non-null int32\n",
      "top-2      206209 non-null int32\n",
      "top-3      206209 non-null int32\n",
      "top-4      206209 non-null int32\n",
      "top-5      206209 non-null int32\n",
      "top-6      206209 non-null int32\n",
      "top-7      206209 non-null int32\n",
      "top-8      206209 non-null int32\n",
      "top-9      206209 non-null int32\n",
      "top-10     206209 non-null int32\n",
      "dtypes: int32(11)\n",
      "memory usage: 8.7 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print ga.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ga.to_hdf(FVARS_STORE, \"ua_top10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    del ps, phist, ga, b_feat\n",
    "except:\n",
    "    pass\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
